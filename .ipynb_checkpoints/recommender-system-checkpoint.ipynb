{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_dir = './data/'\n",
    "ratings = pd.read_csv(data_dir+\"ratings.dat\", \n",
    "                      sep = \"::\", \n",
    "                      engine='python', \n",
    "                      header=None, \n",
    "                      names=['UserID','MovieID','Rating','Timestamp'])\n",
    "users = pd.read_csv(data_dir+\"users.dat\", \n",
    "                      sep = \"::\", \n",
    "                      engine='python', \n",
    "                      header=None, \n",
    "                      names=['UserID','Gender','Age','Occupation','Zip-code'])\n",
    "movies = pd.read_csv(data_dir+\"movies.dat\", \n",
    "                      sep = \"::\", \n",
    "                      engine='python', \n",
    "                      header=None, \n",
    "                      names=['MovieID','Title','Genres'])\n",
    "\n",
    "#- Some MovieIDs do not correspond to a movie due to accidental duplicateentries and/or test entries\n",
    "#- Movies are mostly entered by hand, so errors and inconsistencies may exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform userID and movie Id\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(users.UserID)\n",
    "le.classes_\n",
    "users.UserID = le.transform(users.UserID) \n",
    "ratings.UserID = le.transform(ratings.UserID)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(movies.MovieID)\n",
    "le.classes_\n",
    "movies.MovieID = le.transform(movies.MovieID) \n",
    "ratings.MovieID = le.transform(ratings.MovieID)\n",
    "\n",
    "# split train and test set\n",
    "R_train, R_test = train_test_split(ratings, test_size=0.3, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training set: 700146.\n",
      "Size of Test set: 300063.\n",
      "Number of Users: 6040.\n",
      "Number of Movies: 3883\n"
     ]
    }
   ],
   "source": [
    "train_size = R_train.shape[0]\n",
    "test_size = R_test.shape[0]\n",
    "num_users = len(set(users.UserID.values))\n",
    "num_movies = len(set(movies.MovieID.values))\n",
    "\n",
    "\n",
    "print(f\"Size of Training set: {train_size}.\")\n",
    "print(f\"Size of Test set: {test_size}.\")\n",
    "print(f\"Number of Users: {num_users}.\")\n",
    "print(f\"Number of Movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem():\n",
    "    \n",
    "    def __init__(self, F, num_users, num_movies):\n",
    "        np.random.seed(0)\n",
    "        # initialize bias\n",
    "        self.bu = np.random.normal(loc=0.0, scale=1e-4, size=num_users)\n",
    "        self.bi = np.random.normal(loc=0.0, scale=1e-4, size=num_movies)  \n",
    "        \n",
    "        # initialize latent feature matrix\n",
    "        self.pu = np.random.normal(loc=0.0, scale=1./max(1,np.sqrt(F)), size=[num_users,F])\n",
    "        self.qi = np.random.normal(loc=0.0, scale=1./max(1,np.sqrt(F)), size=[num_movies,F])  \n",
    "        \n",
    "    def loss(self,R_new=None):\n",
    "        if R_new is None:\n",
    "            users = self.R['UserID'].values\n",
    "            movies = self.R['MovieID'].values\n",
    "            ratings = self.R['Rating'].values\n",
    "        else:\n",
    "            users = R_new['UserID'].values\n",
    "            movies = R_new['MovieID'].values\n",
    "            ratings = R_new['Rating'].values\n",
    "    \n",
    "        r_pred = self.miu + self.bu[users] + self.bi[movies] +np.sum(\n",
    "            np.multiply(self.pu[users], self.qi[movies]),axis=1) \n",
    "\n",
    "        return np.mean(np.square(r_pred -ratings ))\n",
    "    \n",
    "    def train(self, R, penalty=1e-3, learning_rate=1e-3, tol=1e-5, epoch=10, batch_size= 2000):\n",
    "        self.R = R\n",
    "        self.miu = np.mean(self.R.Rating)\n",
    "        \n",
    "        loss0 = self.loss()\n",
    "        loss_lst = []\n",
    "        \n",
    "        for e in range(epoch):\n",
    "            for i in range(0, self.R.shape[0], batch_size):\n",
    "                users = self.R['UserID'].values[i:i+batch_size]\n",
    "                movies = self.R['MovieID'].values[i:i+batch_size]\n",
    "                ratings = self.R['Rating'].values[i:i+batch_size]\n",
    "\n",
    "                r_pred = miu + bu[self.R['UserID']] + bi[self.R['MovieID']]\n",
    "                pred_error = ratings-r_pred[i:i+batch_size]\n",
    "                \n",
    "                self.bu[users] += learning_rate * pred_error\n",
    "                self.bi[movies] += learning_rate * pred_error\n",
    "                self.pu[users] += learning_rate*(np.multiply(\n",
    "                    self.qi[movies], pred_error.reshape(-1,1))-penalty*self.pu[users])\n",
    "                self.qi[movies] += learning_rate*(np.multiply(\n",
    "                    self.pu[users], pred_error.reshape(-1,1))-penalty*self.qi[movies])\n",
    "            \n",
    "            loss = self.loss()\n",
    "            loss_lst.append(loss)\n",
    "\n",
    "            print(f\"Epoch {e}: loss {loss}.\")\n",
    "            d = np.abs(loss-loss0)\n",
    "            if d<tol*loss0:\n",
    "                break\n",
    "            loss0=loss\n",
    "    \n",
    "    def predict(self,R_new):\n",
    "        return self.loss(R_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 1.0679758950031966.\n",
      "Epoch 1: loss 0.9457522756203176.\n",
      "Epoch 2: loss 0.8798357774916524.\n",
      "Epoch 3: loss 0.8702264006172009.\n",
      "Epoch 4: loss 0.9169241449969636.\n"
     ]
    }
   ],
   "source": [
    "recommender = RecommenderSystem(F=0,num_users= num_users,num_movies=num_movies)\n",
    "recommender.train(R_train, epoch=5, batch_size=2000, learning_rate =0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With learning rate =0.01, the optimization process converge very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9493841322331164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.predict(R_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 2.209493437232628.\n",
      "Epoch 1: loss 2.190361438371178.\n",
      "Epoch 2: loss 2.1729209286144426.\n",
      "Epoch 3: loss 2.1571796562271905.\n",
      "Epoch 4: loss 2.143148721800058.\n",
      "Epoch 5: loss 2.1308426352953815.\n",
      "Epoch 6: loss 2.1202793892689478.\n",
      "Epoch 7: loss 2.111480548767233.\n",
      "Epoch 8: loss 2.1044713585122006.\n",
      "Epoch 9: loss 2.0992808681039317.\n",
      "Epoch 0: loss 1.564895666958643.\n",
      "Epoch 1: loss 1.5434580936881657.\n",
      "Epoch 2: loss 1.5229915909565355.\n",
      "Epoch 3: loss 1.5034967835699136.\n",
      "Epoch 4: loss 1.484975563434647.\n",
      "Epoch 5: loss 1.467431108743002.\n",
      "Epoch 6: loss 1.4508679096365897.\n",
      "Epoch 7: loss 1.435291800558143.\n",
      "Epoch 8: loss 1.4207099995502943.\n",
      "Epoch 9: loss 1.4071311548106544.\n",
      "Epoch 0: loss 1.4292303462999405.\n",
      "Epoch 1: loss 1.407118767378108.\n",
      "Epoch 2: loss 1.385821067583781.\n",
      "Epoch 3: loss 1.3653347299777476.\n",
      "Epoch 4: loss 1.3456580083264864.\n",
      "Epoch 5: loss 1.3267899237492653.\n",
      "Epoch 6: loss 1.3087302652247417.\n",
      "Epoch 7: loss 1.291479593951426.\n",
      "Epoch 8: loss 1.275039251583362.\n",
      "Epoch 9: loss 1.2594113723894138.\n",
      "Epoch 0: loss 1.366992114246593.\n",
      "Epoch 1: loss 1.3449621885068679.\n",
      "Epoch 2: loss 1.3236711976474274.\n",
      "Epoch 3: loss 1.3031166682668398.\n",
      "Epoch 4: loss 1.2832966419961802.\n",
      "Epoch 5: loss 1.2642096726090275.\n",
      "Epoch 6: loss 1.245854825581089.\n",
      "Epoch 7: loss 1.2282316801113846.\n",
      "Epoch 8: loss 1.2113403336333313.\n",
      "Epoch 9: loss 1.1951814088609427.\n",
      "Epoch 0: loss 1.3328371185909507.\n",
      "Epoch 1: loss 1.3108022268901143.\n",
      "Epoch 2: loss 1.2894716613583297.\n",
      "Epoch 3: loss 1.2688429851670873.\n",
      "Epoch 4: loss 1.2489141816725253.\n",
      "Epoch 5: loss 1.2296836530442088.\n",
      "Epoch 6: loss 1.211150220926418.\n",
      "Epoch 7: loss 1.1933131291640942.\n",
      "Epoch 8: loss 1.176172048640281.\n",
      "Epoch 9: loss 1.1597270842872223.\n"
     ]
    }
   ],
   "source": [
    "Fs = [1,3,5,7,9]\n",
    "mse = []\n",
    "for f in Fs:\n",
    "    recommender = RecommenderSystem(F=f,num_users= num_users,num_movies=num_movies)\n",
    "    recommender.train(R_train, epoch=10, batch_size=2000, learning_rate =0.001)\n",
    "    mse.append(recommender.predict(R_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
